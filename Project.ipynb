{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4face4f",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "　　　　This project analyzes supply chain data to identify key trends, risks, and opportunities for business improvement. The dataset is sourced from Kaggle (DataCo Smart Supply Chain for Big Data Analysis : https://www.kaggle.com/datasets/shashwatwork/dataco-smart-supply-chain-for-big-data-analysis?select=DescriptionDataCoSupplyChain.csv).Usinga this data, we assess delivery performance, profitability, and customer behaviors. The goal is to discover critical strengths and weaknesses that impact overall revenue and efficiency.\n",
    "\n",
    "　　　　Through visual analytics and statistical evaluation, this report highlights actionable findings. The analysis aims to support decision-makers in prioritizing improvements that will increase profit and optimize operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b79bcb",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Import csv files\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install seaborn\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import sql\n",
    "from sqlalchemy import create_engine, text\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbef429",
   "metadata": {},
   "source": [
    "### create .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Test if variables are loaded\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "database_url = os.getenv(\"DATABASE_URL\")\n",
    "secret_key = os.getenv(\"SECRET_KEY\")\n",
    "debug_mode = os.getenv(\"DEBUG\")\n",
    "\n",
    "# file path\n",
    "supply_chain_file_path = \"../resources/DataCoSupplyChainDataset.csv\"\n",
    "access_log_file_path = \"../resources/tokenized_access_logs.csv\"\n",
    "\n",
    "print(\"✓ Environment variables loaded:\")\n",
    "# print(f\"DB_HOST: {os.getenv('DB_HOST')}\")\n",
    "# print(f\"DB_NAME: {os.getenv('DB_NAME')}\")\n",
    "# print(f\"DB_USER: {os.getenv('DB_USER')}\")\n",
    "# print(f\"DB_PASSWORD: {os.getenv('DB_PASSWORD')}\")\n",
    "# print(f\"DB_PORT: {os.getenv('DB_PORT')}\")\n",
    "# print(f\"Database URL: {database_url}\")\n",
    "# print(f\"Secret Key: {secret_key}\")\n",
    "# print(f\"Debug Mode: {debug_mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa3892",
   "metadata": {},
   "source": [
    "## Create Tables and Import Data Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import sql\n",
    "\n",
    "conn_params = {\n",
    "    'host':     db_host,\n",
    "    'database': db_name,\n",
    "    'user':     db_user,\n",
    "    'password': db_password,\n",
    "    'port':     db_port\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE DATABASE final_project;\")\n",
    "    print(\"Database created successfully!\")\n",
    "    \n",
    "except psycopg2.errors.DuplicateDatabase:\n",
    "    print(\"Database already exists\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e0f16",
   "metadata": {},
   "source": [
    "### Create Tables from Your CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your project database\n",
    "conn_params['database'] = os.getenv('DB_NAME')\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create table with proper data types\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS supply_chain_df (\n",
    "        type VARCHAR(50),\n",
    "        days_for_shipping_real INTEGER,\n",
    "        days_for_shipment_scheduled INTEGER,\n",
    "        benefit_per_order NUMERIC(10,2),\n",
    "        sales_per_customer NUMERIC(10,2),\n",
    "        delivery_status VARCHAR(50),\n",
    "        late_delivery_risk INTEGER,\n",
    "        category_id INTEGER,\n",
    "        category_name VARCHAR(100),\n",
    "        customer_city VARCHAR(100),\n",
    "        customer_country VARCHAR(100),\n",
    "        customer_email VARCHAR(150),\n",
    "        customer_fname VARCHAR(100),\n",
    "        customer_id INTEGER,\n",
    "        customer_lname VARCHAR(100),\n",
    "        customer_password VARCHAR(100),\n",
    "        customer_segment VARCHAR(50),\n",
    "        customer_state VARCHAR(100),\n",
    "        customer_street VARCHAR(200),\n",
    "        customer_zipcode VARCHAR(20),\n",
    "        department_id INTEGER,\n",
    "        department_name VARCHAR(100),\n",
    "        latitude NUMERIC(10,6),\n",
    "        longitude NUMERIC(10,6),\n",
    "        market VARCHAR(50),\n",
    "        order_city VARCHAR(100),\n",
    "        order_country VARCHAR(100),\n",
    "        order_customer_id INTEGER,\n",
    "        order_date DATE,\n",
    "        order_id INTEGER PRIMARY KEY,\n",
    "        order_item_cardprod_id INTEGER,\n",
    "        order_item_discount NUMERIC(10,2),\n",
    "        order_item_discount_rate NUMERIC(5,4),\n",
    "        order_item_id INTEGER,\n",
    "        order_item_product_price NUMERIC(10,2),\n",
    "        order_item_profit_ratio NUMERIC(5,4),\n",
    "        order_item_quantity INTEGER,\n",
    "        sales NUMERIC(10,2),\n",
    "        order_item_total NUMERIC(10,2),\n",
    "        order_profit_per_order NUMERIC(10,2),\n",
    "        order_region VARCHAR(50),\n",
    "        order_state VARCHAR(100),\n",
    "        order_status VARCHAR(50),\n",
    "        order_zipcode VARCHAR(20),\n",
    "        product_card_id INTEGER,\n",
    "        product_category_id INTEGER,\n",
    "        product_description TEXT,\n",
    "        product_image VARCHAR(200),\n",
    "        product_name VARCHAR(200),\n",
    "        product_price NUMERIC(10,2),\n",
    "        product_status INTEGER,\n",
    "        shipping_date DATE,\n",
    "        shipping_mode VARCHAR(50)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(\"✓ Table created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()\n",
    "    \n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ecbba",
   "metadata": {},
   "source": [
    "### Import DataCoSupplyChainDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_url = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "supply_chain_df = pd.read_csv('resources/DataCoSupplyChainDataset.csv')\n",
    "supply_chain_df.columns = supply_chain_df.columns.str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "supply_chain_df.to_sql('supply_chain_df', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"✓ Successfully imported {len(supply_chain_df)} rows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085e26a",
   "metadata": {},
   "source": [
    "### Import tokenized_access_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # CREATE TABLE SQL statement\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS access_log_df (\n",
    "        product VARCHAR(200),\n",
    "        category VARCHAR(100),\n",
    "        date DATE,\n",
    "        month VARCHAR(20),\n",
    "        hour TIME,\n",
    "        department VARCHAR(100),\n",
    "        ip VARCHAR(50),\n",
    "        url TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"✓ Table created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "access_log_df = pd.read_csv('resources/tokenized_access_logs.csv')\n",
    "access_log_df.columns = access_log_df.columns.str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "access_log_df.to_sql('access_log_df', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"✓ Successfully imported {len(access_log_df)} rows!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL query\n",
    "conn = psycopg2.connect(**conn_params)\n",
    "cur = conn.cursor()\n",
    "query = \"SELECT * FROM supply_chain_df;\"\n",
    "supply_chain_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Convert to lowercase all\n",
    "for col in supply_chain_df.select_dtypes(include=['object']).columns:\n",
    "    supply_chain_df[col] = supply_chain_df[col].str.lower()\n",
    "\n",
    "supply_chain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eddf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log_df = pd.read_sql_query(\"SELECT * FROM access_log_df\", conn)\n",
    "\n",
    "for col in access_log_df.select_dtypes(include=['object']).columns:\n",
    "    access_log_df[col] = access_log_df[col].str.lower()\n",
    "\n",
    "access_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc626693",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdfb0f",
   "metadata": {},
   "source": [
    "# 2. Data Analysis\n",
    "- Delivery Performance Analysis: Investigate shipping risks and delivery times.\n",
    "\n",
    "- Financial Performance Analysis: Review profit and loss by payment type and category.\n",
    "\n",
    "- Customer & Geographic Analysis: Examine results by customer segments and regions.\n",
    "\n",
    "- Product & Category Performance: Compare top products and categories.\n",
    "\n",
    "- Website Traffic Analysis: Analyze site visits and peak hours.\n",
    "\n",
    "- Web Traffic vs. Sales Conversion: Identify departments with high traffic and low sales.\n",
    "\n",
    "- Executive Summary & Recommendations: Summarize insights and propose actions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e344b",
   "metadata": {},
   "source": [
    "# 3. Insights & Interpretation\n",
    "## Key findings, trends, and interpretations\n",
    "- Delivery delays are more frequent in specific shipping modes, affecting customer satisfaction and revenue.\n",
    "\n",
    "- Loss-making product categories were consistently identified, requiring targeted fix.\n",
    "\n",
    "- Certain customer segments and regions show stronger sales performance and higher profitability.\n",
    "\n",
    "- Website traffic patterns highlight peak hours, but some departments fail to convert visits into sales efficiently.\n",
    "\n",
    "#### The biggest opportunities for revenue recovery in the following areas:\n",
    "\n",
    "**Improving sales conversion**:   \n",
    "Many website visitors do not complete purchases. Targeting departments and processes with high traffic but low conversion rates can unlock substantial new revenue.\n",
    "\n",
    "**Fixing late deliveries**:    \n",
    "Orders with high delivery risk result in customer dissatisfaction and lost sales. Optimizing shipping and logistics processes will directly boost results.\n",
    "\n",
    "**Boosting top product categories**:    \n",
    "The most profitable categories still have room for growth. Focused marketing and operations improvements here can yield significant gains.\n",
    "\n",
    "These trends highlight where changes can make the most impact. \n",
    "\n",
    "\n",
    "\n",
    "## Main strengths and weaknesses \n",
    "### Strengths\n",
    "\n",
    "- Strong profitable categories - leverage these\n",
    "\n",
    "-  Good market presence - multiple profitable markets\n",
    "\n",
    "-  High web traffic - strong online presence\n",
    "-  Identifiable peak hours - optimize operations\n",
    "\n",
    "### Weaknesses\n",
    "\n",
    "- High late delivery risk impacts sales and reputation.\n",
    "\n",
    "- Several product categories are unprofitable.\n",
    "\n",
    "- Conversion gaps lead to missed potential revenue.\n",
    "\n",
    "- Loss-making categories.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f53f7c",
   "metadata": {},
   "source": [
    "# 4. Recommendations\n",
    "\n",
    "Based on the findings, we recommend focusing on the following actions to improve business results:\n",
    "\n",
    "- Address late delivery risks by optimizing shipping methods and logistics processes.\n",
    "\n",
    "- Eliminate or fix unprofitable payment types and product categories to improve profitability.\n",
    "\n",
    "- Enhance sales conversion rates by targeting departments and segments with high traffic but low sales.\n",
    "\n",
    "- Leverage strongest customer segments and regions for marketing and expansion efforts.\n",
    "\n",
    "- Monitor website traffic and sales alignment to ensure growth opportunities are not missed.\n",
    "\n",
    "- Implementing these actions can help unlock significant revenue opportunity and strengthen overall business performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b926c",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "\n",
    "   Our analysis provides a clear overview of the supply chain and sales performance, revealing both strengths and areas for improvement. This demonstrates that it can drive the largest business improvements to focus on better sales conversion, delivery performance, and top category growth. By prioritizing these high-potential areas, the company could increase profitability and achieve sustainable growth. Continuous monitoring and action on these key issues would be essential for future success.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c0252",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
